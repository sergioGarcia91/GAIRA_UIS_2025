{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO6b2Br27L9BkB7JZgFQkBf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergioGarcia91/GAIRA_UIS_2025/blob/main/01_GAIRA_Labelme2yolov8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción\n",
        "\n",
        "En este Notebook se describe el flujo de trabajo para convertir anotaciones de imágenes realizadas con [LabelMe](https://github.com/wkentaro/labelme) al formato requerido por [YOLOv8](https://docs.ultralytics.com/models/yolov8/), usando la librería `labelme2yolov8`. De este modo podrás preparar fácilmente tus datos segmentados y entrenar o reentrenar modelos basados en YOLOv8.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wvn2IqySHPSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inicio"
      ],
      "metadata": {
        "id": "3tPCbY9tUoO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalación\n",
        "Para instalar la librería que convierte anotaciones de LabelMe al formato de YOLOv8 se debe ejecutar:\n",
        "\n",
        "```bash\n",
        "!pip install labelme2yolov8\n",
        "````\n",
        "\n",
        "Si ya la tienes instalada y quieres actualizar a la versión más reciente:\n",
        "\n",
        "```bash\n",
        "!pip install --upgrade labelme2yolov8\n",
        "```\n",
        "\n",
        "Para consultar todos los parámetros y opciones de configuración, revisa la documentación oficial en GitHub:\n",
        "[labelme2yolov8 · GitHub](https://github.com/spatiallysaying/labelme2yolov8)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IytXC82CI5pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Instalación de la librería labelme2yolov8\n",
        "!pip install labelme2yolov8"
      ],
      "metadata": {
        "id": "XsfNbrJXJAVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conexión con Google Drive"
      ],
      "metadata": {
        "id": "nlVriPaVJoX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para acceder a archivos almacenados en tu unidad de Google Drive desde este Notebook\n",
        "from google.colab import drive\n",
        "\n",
        "# Monta tu Google Drive en el directorio /content/drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW8x0-ehUnBs",
        "outputId": "6e81f55b-99cf-4144-c984-156b5b6e143e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversión de anotaciones\n",
        "\n",
        "Para preparar los datos para YOLOv8, ejecuta la siguiente celda. Se generarán automáticamente la carpeta `YOLOv8Dataset` que contiene las carpetas `train` y `val` con las imágenes y etiquetas en el formato correcto:\n",
        "\n",
        "```bash\n",
        "!python -m labelme2yolov8\n",
        "    --json_dir \"/content/drive/MyDrive/carpeta/con/las/imagenes\"\n",
        "    --val_size 0.2\n",
        "````\n",
        "\n",
        "Opciones adicionales:\n",
        "\n",
        "* `--output_dir`: directorio de salida para los datos convertidos (por defecto, se crea `yolov8_data` junto a `json_dir`).\n",
        "* `--train_size`: en lugar de `--val_size`, define directamente la proporción de entrenamiento (p. ej. `0.8`).\n",
        "* `--classes`: ruta a un archivo `.txt` con la lista de clases, si prefieres un orden distinto al alfabético por defecto.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l-zQV9EXJ1B_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para proceder a convertir los datos a YOLO\n",
        "!python -m labelme2yolov8 --json_dir /content/drive/MyDrive/Rocas/Fotos_GAIRA_labelme --val_size 0.2"
      ],
      "metadata": {
        "id": "xYMVca2V--GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observaciones:\n",
        "\n",
        "> 1. Después de la conversión, revisa que la estructura de carpetas `train` y `val` contenga correctamente las imágenes y sus archivos de etiqueta correspondientes.  \n",
        "> 2. Verifica el archivo `dataset.yaml`, que define las rutas de los conjuntos de entrenamiento y validación, el número de clases y sus nombres. Su formato debería ser similar al siguiente:\n",
        ">    ```yaml\n",
        ">    train: /content/drive/MyDrive/ruta/a/la/carpeta/YOLOv8Dataset/train\n",
        ">    val:   /content/drive/MyDrive/ruta/a/la/carpeta/YOLOv8Dataset/val\n",
        ">    nc: 3\n",
        ">    names: [\"Roca metamórfica\", \"Roca ígnea\", \"Roca sedimentaria\"]\n",
        ">    ```\n",
        "> 3. El orden de los elementos en `names` establece la correspondencia entre el índice de etiqueta y la clase. **No modificar este orden** al incorporar nuevos datos, ya que cualquier cambio puede provocar desajustes en futuros reentrenamientos.\n"
      ],
      "metadata": {
        "id": "MiWjlojuKY6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FIn"
      ],
      "metadata": {
        "id": "a3L1_vADUqSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgajoDhAUi6R"
      },
      "outputs": [],
      "source": []
    }
  ]
}